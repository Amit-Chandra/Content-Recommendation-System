{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47bd67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-clientNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for google-api-python-client from https://files.pythonhosted.org/packages/1c/8a/12a389757b025dda3d6df29c4143dd896a3cd837f00587e162ad4baf3d31/google_api_python_client-2.139.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_api_python_client-2.139.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\amitc\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\amitc\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for httplib2<1.dev0,>=0.19.0 from https://files.pythonhosted.org/packages/a8/6c/d2fbdaaa5959339d53ba38e94c123e4e84b8fbc4b84beb0e70d7c1608486/httplib2-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 from https://files.pythonhosted.org/packages/e7/00/85c22f7f73fa2e88dfbf0e1f63c565386ba40e0264b59c8a4362ae27c9fc/google_auth-2.32.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-auth-httplib2<1.0.0,>=0.2.0 from https://files.pythonhosted.org/packages/be/8a/fe34d2f3f9470a27b01c9e76226965863f153d5fbe276f83608562e49c04/google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Obtaining dependency information for google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 from https://files.pythonhosted.org/packages/44/99/daa3541e8ecd7d8b7907b714ba92126097a976b5b3dbabdb5febdcf08554/google_api_core-2.19.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Obtaining dependency information for uritemplate<5,>=3.0.1 from https://files.pythonhosted.org/packages/81/c0/7461b49cd25aeece13766f02ee576d1db528f1c37ce69aee300e075b485b/uritemplate-4.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/02/48/87422ff1bddcae677fb6f58c97f5cfc613304a5e8ce2c3662760199c0a84/googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.21.12)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.3 from https://files.pythonhosted.org/packages/7c/6f/db31f0711c0402aa477257205ce7d29e86a75cb52cd19f7afb585f75cda0/proto_plus-1.24.0-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/04/e6/a1551acbaa06f3e48b311329828a34bc9c51a8cfaecdeb4d03c329a1ef85/cachetools-5.4.0-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amitc\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.7.22)\n",
      "Downloading google_api_python_client-2.139.0-py2.py3-none-any.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.1 MB 7.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/12.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.9/12.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/12.1 MB 16.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.3/12.1 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 18.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.5/12.1 MB 19.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.5/12.1 MB 20.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.6/12.1 MB 17.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.9/12.1 MB 16.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 17.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.1 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.4/139.4 kB ? eta 0:00:00\n",
      "Downloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "   ---------------------------------------- 0.0/195.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 195.5/195.5 kB 12.4 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 220.0/220.0 kB ? eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: uritemplate, rsa, proto-plus, httplib2, googleapis-common-protos, cachetools, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.4.0 google-api-core-2.19.1 google-api-python-client-2.139.0 google-auth-2.32.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.63.2 httplib2-0.22.0 proto-plus-1.24.0 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b931c9",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e5d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id                                              title  \\\n",
      "0  Ks-_Mh1QhMc  Your body language may shape who you are | Amy...   \n",
      "1  dQw4w9WgXcQ  Rick Astley - Never Gonna Give You Up (Officia...   \n",
      "\n",
      "                                         description  \\\n",
      "0  Body language affects how others see us, but i...   \n",
      "1  The official video for â€œNever Gonna Give You U...   \n",
      "\n",
      "                                                tags category_id  view_count  \\\n",
      "0  [Amy Cuddy, TED, TEDTalk, TEDTalks, TED Talk, ...          22    25232908   \n",
      "1  [rick astley, Never Gonna Give You Up, nggyu, ...          10  1560490912   \n",
      "\n",
      "   like_count  comment_count  \n",
      "0      445821           9861  \n",
      "1    17768799        2351103  \n"
     ]
    }
   ],
   "source": [
    "# notebooks/test_youtube_api.py\n",
    "from app.youtube_api import YouTubeAPI\n",
    "\n",
    "# Initialize the API object\n",
    "api = YouTubeAPI()\n",
    "\n",
    "# Example video IDs\n",
    "video_ids = ['Ks-_Mh1QhMc', 'dQw4w9WgXcQ']\n",
    "\n",
    "# Fetch video details\n",
    "video_df = api.get_video_details(video_ids)\n",
    "\n",
    "# Print the results\n",
    "print(video_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c8d54",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e994a86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter search query: machine learning tutorial\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_components(50) must be <= n_features(10).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m user_item_df \u001b[38;5;241m=\u001b[39m generate_user_item_data(user_ids, video_ids)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Train collaborative filtering model\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m user_factors, item_factors \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_collaborative_filtering\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_item_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Calculate content similarity\u001b[39;00m\n\u001b[0;32m     81\u001b[0m content_similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
      "File \u001b[1;32mD:\\The World of Programming\\Github\\Content-Recommendation-System\\app\\recommendation.py:26\u001b[0m, in \u001b[0;36mtrain_collaborative_filtering\u001b[1;34m(user_item_df)\u001b[0m\n\u001b[0;32m     23\u001b[0m interaction_sparse_matrix \u001b[38;5;241m=\u001b[39m csr_matrix(interaction_matrix)\n\u001b[0;32m     25\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m user_factors \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction_sparse_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m item_factors \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mcomponents_\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_factors, item_factors\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:242\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be <=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m n_features(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m     U, Sigma, VT \u001b[38;5;241m=\u001b[39m randomized_svd(\n\u001b[0;32m    247\u001b[0m         X,\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[0;32m    253\u001b[0m     )\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_ \u001b[38;5;241m=\u001b[39m VT\n",
      "\u001b[1;31mValueError\u001b[0m: n_components(50) must be <= n_features(10)."
     ]
    }
   ],
   "source": [
    "# content-recommendation-system.ipynb\n",
    "\n",
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from app.youtube_api import YouTubeAPI\n",
    "from app.recommendation import preprocess_data, train_collaborative_filtering, get_content_recommendations\n",
    "from googleapiclient.errors import HttpError\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize YouTube API\n",
    "youtube_api = YouTubeAPI()  # No need to pass API key as it's read from the environment variable\n",
    "\n",
    "# Function to fetch video IDs based on a search query or other criteria\n",
    "def fetch_video_ids(query, max_results=10):\n",
    "    try:\n",
    "        search_response = youtube_api.youtube.search().list(\n",
    "            q=query,\n",
    "            part='id',\n",
    "            maxResults=max_results,\n",
    "            type='video'\n",
    "        ).execute()\n",
    "\n",
    "        video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]\n",
    "        return video_ids\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Get search query from user input\n",
    "search_query = input(\"Enter search query: \")\n",
    "\n",
    "if not search_query:\n",
    "    raise ValueError(\"Search query cannot be empty.\")\n",
    "\n",
    "# Fetch video IDs based on user input\n",
    "video_ids = fetch_video_ids(search_query, max_results=10)\n",
    "\n",
    "if not video_ids:\n",
    "    raise ValueError(\"No video IDs found for the search query.\")\n",
    "\n",
    "# Get video details\n",
    "video_df = youtube_api.get_video_details(video_ids)\n",
    "\n",
    "# Preprocess data\n",
    "video_df, tfidf_matrix = preprocess_data(video_df)\n",
    "\n",
    "# Function to dynamically generate user-item interaction data\n",
    "def generate_user_item_data(user_ids, video_ids):\n",
    "    user_item_data = {\n",
    "        'user_id': [],\n",
    "        'video_id': [],\n",
    "        'interaction': []\n",
    "    }\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        for video_id in video_ids:\n",
    "            # Simulate interaction data (e.g., based on some logic or actual data)\n",
    "            interaction = np.random.choice([0, 1], p=[0.5, 0.5])  # Randomly assign interaction\n",
    "            user_item_data['user_id'].append(user_id)\n",
    "            user_item_data['video_id'].append(video_id)\n",
    "            user_item_data['interaction'].append(interaction)\n",
    "    \n",
    "    return pd.DataFrame(user_item_data)\n",
    "\n",
    "# Sample user IDs (should be fetched dynamically from your actual user data source)\n",
    "user_ids = ['user1', 'user2', 'user3']\n",
    "\n",
    "# Generate user-item interaction data dynamically\n",
    "user_item_df = generate_user_item_data(user_ids, video_ids)\n",
    "\n",
    "# Train collaborative filtering model\n",
    "user_factors, item_factors = train_collaborative_filtering(user_item_df)\n",
    "\n",
    "# Calculate content similarity\n",
    "content_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Save preprocessed data and models\n",
    "video_df.to_csv('../data/video_metadata.csv', index=False)\n",
    "user_item_df.to_csv('../data/user_watch_history.csv', index=False)\n",
    "np.save('../data/user_factors.npy', user_factors)\n",
    "np.save('../data/item_factors.npy', item_factors)\n",
    "np.save('../data/content_similarity.npy', content_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21157fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample user-item interaction data\n",
    "data = {\n",
    "    'user_id': ['user1', 'user1', 'user2', 'user2', 'user3'],\n",
    "    'video_id': ['video1', 'video2', 'video1', 'video3', 'video4'],\n",
    "    'interaction': [1, 1, 1, 1, 1]  # Binary interactions\n",
    "}\n",
    "\n",
    "user_item_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2be3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e34257f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix shape: (3, 4)\n",
      "Using n_components: 4\n",
      "User factors shape: (3, 3)\n",
      "Item factors shape: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "def train_collaborative_filtering(user_item_df):\n",
    "    interaction_matrix = user_item_df.pivot(index='user_id', columns='video_id', values='interaction').fillna(0)\n",
    "    print(\"Interaction matrix shape:\", interaction_matrix.shape)\n",
    "    interaction_sparse_matrix = csr_matrix(interaction_matrix)\n",
    "    \n",
    "    n_components = min(50, interaction_sparse_matrix.shape[1])\n",
    "    print(f\"Using n_components: {n_components}\")  # Debugging output\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    user_factors = svd.fit_transform(interaction_sparse_matrix)\n",
    "    item_factors = svd.components_.T\n",
    "    \n",
    "    return user_factors, item_factors\n",
    "\n",
    "# Run the function with sample data\n",
    "user_factors, item_factors = train_collaborative_filtering(user_item_df)\n",
    "\n",
    "\n",
    "print(\"User factors shape:\", user_factors.shape)\n",
    "print(\"Item factors shape:\", item_factors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68214831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
